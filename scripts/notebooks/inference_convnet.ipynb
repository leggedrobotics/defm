{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d81c0d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2026, ETH Zurich, Manthan Patel\n",
    "#\n",
    "# This source code is licensed under the Apache License, Version 2.0\n",
    "# found in the LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root (defm) to sys.path\n",
    "root_dir = Path(os.getcwd()).parent.parent.resolve() \n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "from defm.utils import preprocess_depth_image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model_list = [\"defm_efficientnet_b0\",\n",
    "              \"defm_efficientnet_b2\",\n",
    "              \"defm_efficientnet_b4\",\n",
    "              \"defm_efficientnet_b6\",\n",
    "              \"defm_resnet18\",\n",
    "              \"defm_resnet34\",\n",
    "              \"defm_resnet50\",\n",
    "              \"defm_regnet_y_400mf\",\n",
    "              \"defm_regnet_y_800mf\",\n",
    "              \"defm_regnet_y_1_6gf\"] # Available DeFM Conv models\n",
    "\n",
    "MODEL_NAME = \"defm_resnet50\" \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load(\n",
    "        repo_or_dir=root_dir, # Path to your DeFM root folder\n",
    "        model=MODEL_NAME,\n",
    "        source='local',\n",
    "        pretrained=True,\n",
    "    )\n",
    "model.eval().to(DEVICE)\n",
    "print(f\"Loaded model: {MODEL_NAME} with {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Inference Example with Dummy Data\n",
    "dummy_depth = torch.randn(160, 192, 1) * 100 # Dummy depth input with max depth 100 meters\n",
    "\n",
    "# Target Size must be a multiple of the patch size\n",
    "# If target size is None, no resizing is applied\n",
    "# For BiFPN, H and W must be multiples of 32\n",
    "# The passed depth image should be in meters\n",
    "# This is very important for correct metric-depth based normalization\n",
    "\n",
    "normalized_depth = preprocess_depth_image(\n",
    "    dummy_depth,\n",
    "    target_size=(160, 192),\n",
    ").to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(normalized_depth)\n",
    "\n",
    "class_token = output['global_backbone'] # [B, C]\n",
    "# Here always use the P4 (H//16, W//16) feature map from BiFPN for spatial tokens as \n",
    "# this was used during distillations to match the ViT spatial tokens\n",
    "spatial_tokens = output['dense_bifpn']['P4'] # [B, C, H', W']\n",
    "\n",
    "print(f\"Output Spatial Tokens: {spatial_tokens.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Class Token: {class_token.shape}\") # (B, C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you dont want to use BiFPN features, use the following instead:\n",
    "# Here the input can have any size \n",
    "with torch.no_grad():\n",
    "    output = model.forward_no_bifpn(normalized_depth)\n",
    "\n",
    "class_token = output['global_backbone'] # [B, C]\n",
    "spatial_tokens = output['dense_feats']['P4'] # [B, C, H//16, W//16]\n",
    "dense_feat_map = output['dense_feats']['P5'] # [B, C, H//32, W//32]\n",
    "\n",
    "print(f\"Output Spatial Tokens: {spatial_tokens.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Dense Feature Map: {dense_feat_map.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Class Token: {class_token.shape}\") # (B, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
