{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d81c0d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root (defm) to sys.path\n",
    "root_dir = Path(os.getcwd()).parent.resolve() \n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "from defm.utils import preprocess_depth_image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model_list = [\"defm_efficientnet_b0\",\n",
    "              \"defm_efficientnet_b2\",\n",
    "              \"defm_efficientnet_b4\",\n",
    "              \"defm_efficientnet_b6\",\n",
    "              \"defm_resnet18\",\n",
    "              \"defm_resnet34\",\n",
    "              \"defm_resnet50\",\n",
    "              \"defm_regnet_y_400mf\",\n",
    "              \"defm_regnet_y_800mf\",\n",
    "              \"defm_regnet_y_1_6gf\"] # Available DeFM Conv models\n",
    "\n",
    "MODEL_NAME = \"defm_resnet50\" \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355fce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patelm/defm/defm/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/patelm/defm/defm/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/patelm/defm/defm/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone resnet50 feature channels: [512, 1024, 2048]\n",
      "Loaded DeFM weights from /home/patelm/defm/weights/defm_resnet50.pth with result: <All keys matched successfully>\n",
      "Loaded model: defm_resnet50 with 26.20M parameters.\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\n",
    "        repo_or_dir='../', # Path to your DeFM root folder\n",
    "        model=MODEL_NAME,\n",
    "        source='local',\n",
    "        pretrained=True,\n",
    "    )\n",
    "model.eval().to(DEVICE)\n",
    "print(f\"Loaded model: {MODEL_NAME} with {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ff58c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Spatial Tokens: torch.Size([1, 256, 10, 12])\n",
      "Output Class Token: torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Forward Inference Example with Dummy Data\n",
    "dummy_depth = torch.randn(160, 192, 1) * 100 # Dummy depth input with max depth 100 meters\n",
    "\n",
    "# Target Size must be a multiple of the patch size\n",
    "# If target size is None, no resizing is applied\n",
    "# For BiFPN, H and W must be multiples of 32\n",
    "# The passed depth image should be in meters\n",
    "# This is very important for correct metric-depth based normalization\n",
    "\n",
    "normalized_depth = preprocess_depth_image(\n",
    "    dummy_depth,\n",
    "    target_size=(160, 192),\n",
    ").to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(normalized_depth)\n",
    "\n",
    "class_token = output['global_backbone'] # [B, C]\n",
    "# Here always use the P4 (H//16, W//16) feature map from BiFPN for spatial tokens as \n",
    "# this was used during distillations to match the ViT spatial tokens\n",
    "spatial_tokens = output['dense_bifpn']['P4'] # [B, C, H', W']\n",
    "\n",
    "print(f\"Output Spatial Tokens: {spatial_tokens.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Class Token: {class_token.shape}\") # (B, C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684dac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Spatial Tokens: torch.Size([1, 1024, 10, 12])\n",
      "Output Dense Feature Map: torch.Size([1, 2048, 5, 6])\n",
      "Output Class Token: torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# If you dont want to use BiFPN features, use the following instead:\n",
    "# Here the input can have any size \n",
    "with torch.no_grad():\n",
    "    output = model.forward_no_bifpn(normalized_depth)\n",
    "\n",
    "class_token = output['global_backbone'] # [B, C]\n",
    "spatial_tokens = output['dense_feats']['P4'] # [B, C, H//16, W//16]\n",
    "dense_feat_map = output['dense_feats']['P5'] # [B, C, H//32, W//32]\n",
    "\n",
    "print(f\"Output Spatial Tokens: {spatial_tokens.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Dense Feature Map: {dense_feat_map.shape}\") # (B, C, H', W')\n",
    "print(f\"Output Class Token: {class_token.shape}\") # (B, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
